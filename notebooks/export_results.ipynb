{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akramzaytar/ssdshared/akramz_datasets/config/miniforge3/envs/wtlv2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "from random import *\n",
    "from datetime import *\n",
    "from IPython.core.debugger import set_trace\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shapely.geometry import *\n",
    "from rasterio.errors import NotGeoreferencedWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=NotGeoreferencedWarning)\n",
    "import rasterio\n",
    "\n",
    "from einops import rearrange\n",
    "import kornia.augmentation as K\n",
    "\n",
    "import torch\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "from torchgeo.trainers import SemanticSegmentationTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.dfc2022_datamodule import DFC2022DataModule\n",
    "from dataloaders.isprs_datamodule import ISPRSDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"potsdam\"\n",
    "method_fn = \"diversityvit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_name = f\"{dataset} {method_fn}\"\n",
    "config_file = f\"jobs/{dataset}.yaml\"\n",
    "gpu = 1\n",
    "device = f\"cuda:{gpu}\"\n",
    "\n",
    "# Get the model directories\n",
    "model_dirs = list(\n",
    "    Path(\"./internal_checkpoints\").glob(method_name.lower().replace(\" \", \"_\") + \"_*\")\n",
    ")\n",
    "percent2models = {}\n",
    "for model_dir in model_dirs:\n",
    "    percent = int(model_dir.name.split(\"_\")[-2])\n",
    "    if percent not in percent2models:\n",
    "        percent2models[percent] = list()\n",
    "    ckpt_files = list(model_dir.glob(\"*.ckpt\"))\n",
    "    ckpt_files = sorted(ckpt_files, key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "    if ckpt_files:\n",
    "        percent2models[percent].append(ckpt_files[0])\n",
    "\n",
    "# Remove empty percent2models\n",
    "percent2models = {k: v for k, v in percent2models.items() if v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potsdam diversityvit (1%) ---->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akramzaytar/ssdshared/akramz_datasets/config/miniforge3/envs/wtlv2/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.524730384349823 0.62951 0.54732 0.59305 0.58652 0.61751 0.17447\n",
      "0.6081923842430115 0.73194 0.76181 0.62475 0.63225 0.71216 0.18624\n",
      "potsdam diversityvit (5%) ---->\n",
      "0.6053739786148071 0.74946 0.78055 0.62973 0.6291 0.70736 0.13604\n",
      "0.6651648283004761 0.79051 0.85004 0.65716 0.70154 0.75366 0.23807\n",
      "potsdam diversityvit (10%) ---->\n",
      "0.6291732788085938 0.75864 0.82048 0.64211 0.67823 0.74181 0.13377\n",
      "0.5777608156204224 0.75275 0.74386 0.60308 0.542 0.69007 0.1348\n",
      "potsdam diversityvit (25%) ---->\n",
      "0.5769183039665222 0.72538 0.7559 0.63139 0.66204 0.58525 0.10155\n",
      "0.5991523265838623 0.72396 0.76751 0.63969 0.65981 0.65751 0.14643\n",
      "potsdam diversityvit (50%) ---->\n",
      "0.6650083065032959 0.77227 0.81546 0.67007 0.69159 0.75852 0.28215\n",
      "0.5896179676055908 0.70507 0.77434 0.63862 0.60585 0.71395 0.09988\n"
     ]
    }
   ],
   "source": [
    "for percentage in [1, 5, 10, 25, 50]:\n",
    "\n",
    "    if not percentage in percent2models:\n",
    "        continue\n",
    "\n",
    "    print(f\"{method_name} ({percentage}%) ---->\")\n",
    "    models = percent2models[percentage]\n",
    "\n",
    "    for ckpt in models:\n",
    "\n",
    "        # pretend that we are working with a single file\n",
    "        config = OmegaConf.load(config_file)\n",
    "        config.evaluation.method_name = method_name\n",
    "        config.datamodule.train_coordinate_file_path = f\"/home/akramzaytar/ssdshared/akramz_datasets/wtlv2/submissions/{dataset}/{method_fn}.txt\"\n",
    "        config.trainer.devices = [gpu]\n",
    "        config.datamodule.root_dir = str(Path.home() / config.datamodule.root_dir)\n",
    "\n",
    "        # Load model\n",
    "        task = SemanticSegmentationTask.load_from_checkpoint(\n",
    "            ckpt, weights=True\n",
    "        )  # A hack\n",
    "        task = task.to(device).half()\n",
    "        task.eval()\n",
    "\n",
    "        # Load datamodule and dataloader\n",
    "        if config.datamodule.dataset == \"DFC2022\":\n",
    "            datamodule = DFC2022DataModule(**config.datamodule)\n",
    "            datamodule.setup()\n",
    "            dataloader = datamodule.test_dataloader()  # batch size is 1\n",
    "            pad = K.PadTo(size=(2048, 2048), pad_mode=\"constant\", pad_value=0.0)\n",
    "            indices = (\n",
    "                torch.Tensor([1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14]).int().to(device)\n",
    "            )  # 12 classes\n",
    "\n",
    "        else:  # vaihingen and potsdam\n",
    "            datamodule = ISPRSDataModule(**config.datamodule)\n",
    "            datamodule.setup()\n",
    "            dataloader = datamodule.test_dataloader()  # batch size is 1\n",
    "            pad = K.PadTo(size=(3840, 3840), pad_mode=\"constant\", pad_value=0.0)\n",
    "            p_pad = K.PadTo(size=(6016, 6016), pad_mode=\"constant\", pad_value=0.0)\n",
    "            indices = torch.Tensor([0, 1, 2, 3, 4, 5]).int().to(device)\n",
    "\n",
    "        jaccard = torch.zeros(6).to(device)\n",
    "        jaccard_metric = MulticlassJaccardIndex(\n",
    "            num_classes=6,\n",
    "            ignore_index=-1,\n",
    "            average=\"none\",\n",
    "        ).to(device)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            x = batch[\"image\"].to(device).half()\n",
    "            height, width = x.shape[-2:]\n",
    "            if (\n",
    "                config.datamodule.dataset == \"DFC2022\"\n",
    "                or config.datamodule.dataset == \"vaihingen\"\n",
    "            ):\n",
    "                x = pad(x)\n",
    "            else:\n",
    "                x = p_pad(x)\n",
    "            preds = task(x)\n",
    "            tmp_preds = preds\n",
    "            preds = preds[0, :, :height, :width]\n",
    "            preds = rearrange(preds, \"c h w -> (h w) c\")\n",
    "            target = batch[\"mask\"].to(device).flatten()\n",
    "            jaccard += jaccard_metric(preds, target)\n",
    "            del [x, preds, target, tmp_preds]\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        ave_jac = jaccard / len(dataloader)\n",
    "        ave_jac_specific_classes = torch.index_select(ave_jac, 0, indices)\n",
    "        scores = [float(torch.mean(ave_jac_specific_classes).cpu().numpy())] + [\n",
    "            round(e, 5) for e in ave_jac_specific_classes.cpu().numpy().tolist()\n",
    "        ]\n",
    "        print(\" \".join(map(str, scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
